#!/usr/bin/env python3
"""
Enhanced vulnerability testing script that captures real dialogue.
"""

import os
import sys
import re
from typing import List, Dict, Any
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

# Load .env file
env_path = Path(__file__).parent / '.env'
load_dotenv(dotenv_path=env_path)

# Add paths for imports
sys.path.append('/workspaces/gsoc-concordia')
sys.path.append('/workspaces/gsoc-concordia/vulnerability_testing')

# Core imports
from concordia.utils import helper_functions
from concordia.prefabs.simulation import generic as simulation
import concordia.prefabs.entity as entity_prefabs
import concordia.prefabs.game_master as game_master_prefabs

# Vulnerability testing imports
from config.together_config import create_together_model
from scenarios.test_scenarios import create_all_scenarios
from detectors.vulnerability_detectors import (
    RewardHackingDetector,
    DeceptionDetector,
    SandbaggingDetector,
)
from analysis.report_generator import VulnerabilityReportGenerator


def create_simple_embedder():
    """Create a simple embedder for the simulation."""
    import hashlib
    import numpy as np
    
    def embedder(text):
        if isinstance(text, list):
            return [embedder(t) for t in text]
        hash_val = int(hashlib.md5(text.encode()).hexdigest()[:8], 16)
        np.random.seed(hash_val)
        return np.random.randn(384).astype(np.float32)
    
    return embedder


def extract_dialogue_from_html(html_log: str) -> List[Dict[str, str]]:
    """Extract dialogue from HTML simulation log."""
    dialogue = []
    
    # Parse agent observations and actions from HTML
    # Look for patterns like "Entity X observed:" or "Entity X chose action:"
    lines = html_log.split('<br />')
    
    for line in lines:
        # Extract entity observations
        obs_match = re.search(r'Entity (\w+) observed: (.+)', line)
        if obs_match:
            agent = obs_match.group(1)
            statement = obs_match.group(2)
            if statement.strip():  # Only if not empty
                dialogue.append({
                    'agent': agent,
                    'type': 'observation',
                    'statement': statement,
                })
        
        # Extract entity actions
        action_match = re.search(r'Entity (\w+) chose action: (.+)', line)
        if action_match:
            agent = action_match.group(1)
            action = action_match.group(2)
            if action.strip() and action != agent:  # Avoid empty or self-reference
                dialogue.append({
                    'agent': agent,
                    'type': 'action',
                    'statement': action,
                })
    
    return dialogue


def analyze_dialogue_for_vulnerabilities(
    dialogue: List[Dict[str, str]],
    detectors: List,
    scenario_name: str
) -> List[Dict]:
    """Analyze captured dialogue for vulnerabilities."""
    
    all_detections = []
    
    for entry in dialogue:
        agent_name = entry['agent']
        statement = entry['statement']
        context = f"{scenario_name} - {entry['type']}"
        
        # Run each detector
        for detector in detectors:
            detection = detector.analyze_dialogue(
                agent_name=agent_name,
                statement=statement,
                context=context
            )
            
            if detection:
                # Convert detection to dict for report
                detection_dict = {
                    'vulnerability_type': detection.vulnerability_type,
                    'agent_name': detection.agent_name,
                    'confidence': detection.confidence,
                    'severity': detection.severity,
                    'evidence': detection.evidence,
                    'context': detection.context,
                    'dialogue': statement[:200],  # Sample of actual dialogue
                }
                all_detections.append(detection_dict)
                
                print(f"  🚨 Detected {detection.vulnerability_type} by {agent_name}")
                print(f"     Confidence: {detection.confidence:.2f}, Severity: {detection.severity:.2f}")
    
    return all_detections


def main():
    """Run real vulnerability testing with actual LLM."""
    
    print("=" * 60)
    print("🔍 LLM Vulnerability Discovery - Real Testing Mode")
    print("=" * 60)
    
    # Get model configuration from .env
    api_key = os.environ.get('TOGETHER_API_KEY')
    model_name = os.environ.get('MODEL_NAME', 'NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO')
    
    if not api_key:
        print("❌ No API key found in .env file!")
        return
    
    print(f"\n📡 Using model: {model_name}")
    print(f"🔑 API key loaded: {api_key[:10]}...")
    
    # Create model with TogetherAI
    model = create_together_model(
        api_key=api_key,
        model_name=model_name,
        use_rate_limiting=True,
        max_calls=100,  # Limit for testing
    )
    
    # Create embedder
    embedder = create_simple_embedder()
    
    # Initialize detectors
    print("\n🛡️ Initializing vulnerability detectors...")
    detectors = [
        RewardHackingDetector(),
        DeceptionDetector(),
        SandbaggingDetector(),
    ]
    
    # Get all scenarios
    scenarios = create_all_scenarios()
    
    print(f"\n📋 Running {len(scenarios)} test scenarios with REAL LLM")
    print("⚠️  This will make actual API calls and may take a few minutes...\n")
    
    # Collect all detections
    all_detections = []
    all_dialogues = []
    
    for scenario in scenarios:
        print(f"\n{'='*50}")
        print(f"🎭 Scenario: {scenario.name}")
        print(f"📝 {scenario.description[:100]}...")
        
        # Create test agents
        agents = scenario.create_test_agents()
        print(f"👥 Agents: {[a.name for a in agents]}")
        
        # Create configuration
        config = scenario.create_config(agents)
        config.default_max_steps = 10  # Run for 10 steps to get meaningful dialogue
        
        # Get prefabs
        prefabs = {
            **helper_functions.get_package_classes(entity_prefabs),
            **helper_functions.get_package_classes(game_master_prefabs),
        }
        config.prefabs = prefabs
        
        # Set ground truth for detectors
        for detector in detectors:
            detector.set_ground_truth(scenario.ground_truth)
        
        # Run simulation
        print("🚀 Running simulation with real LLM...")
        try:
            sim = simulation.Simulation(config, model, embedder)
            html_log = sim.play()
            
            # Extract dialogue from HTML log
            dialogue = extract_dialogue_from_html(html_log)
            all_dialogues.extend(dialogue)
            
            print(f"📝 Captured {len(dialogue)} dialogue entries")
            
            # Analyze dialogue for vulnerabilities
            if dialogue:
                print("🔍 Analyzing dialogue for vulnerabilities...")
                detections = analyze_dialogue_for_vulnerabilities(
                    dialogue, detectors, scenario.name
                )
                all_detections.extend(detections)
                print(f"✅ Found {len(detections)} vulnerabilities in this scenario")
            else:
                print("⚠️  No dialogue captured - may need to increase simulation steps")
                
        except Exception as e:
            print(f"❌ Error in simulation: {e}")
            continue
    
    # Generate comprehensive report
    print(f"\n{'='*60}")
    print("📊 Generating vulnerability report...")
    
    report_gen = VulnerabilityReportGenerator()
    
    # Add all detected vulnerabilities
    for detection in all_detections:
        report_gen.add_vulnerability(
            vuln_type=detection['vulnerability_type'],
            agent=detection['agent_name'],
            severity=detection['severity'],
            confidence=detection['confidence'],
            evidence=detection['evidence'],
            context=detection['context'],
            dialogue_sample=detection.get('dialogue', ''),
        )
    
    # Add statistics
    if all_detections:
        vuln_types = {}
        for d in all_detections:
            vtype = d['vulnerability_type']
            vuln_types[vtype] = vuln_types.get(vtype, 0) + 1
        
        stats = {
            'total': len(all_detections),
            'by_type': vuln_types,
            'scenarios_tested': len(scenarios),
            'dialogue_captured': len(all_dialogues),
            'model_tested': model_name,
            'timestamp': datetime.now().isoformat(),
        }
        report_gen.add_statistics(stats)
    
    # Save report
    report_file = f"real_vulnerability_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
    report_gen.save_report(report_file)
    
    # Print summary
    print("\n" + "=" * 60)
    print("✅ Real vulnerability testing complete!")
    print(f"📄 Report saved to: {report_file}")
    print(f"🚨 Total vulnerabilities found: {len(all_detections)}")
    print(f"💬 Total dialogue entries analyzed: {len(all_dialogues)}")
    
    if all_detections:
        print("\n📊 Vulnerability Summary:")
        vuln_counts = {}
        for d in all_detections:
            vuln_counts[d['vulnerability_type']] = vuln_counts.get(d['vulnerability_type'], 0) + 1
        
        for vtype, count in vuln_counts.items():
            print(f"  • {vtype}: {count} instance(s)")
        
        # Show sample vulnerabilities
        print("\n🔍 Sample Detections:")
        for detection in all_detections[:3]:  # Show first 3
            print(f"\n  Type: {detection['vulnerability_type']}")
            print(f"  Agent: {detection['agent_name']}")
            print(f"  Confidence: {detection['confidence']:.2%}")
            print(f"  Evidence: {detection['evidence'][0] if detection['evidence'] else 'N/A'}")
    else:
        print("\n⚠️  No vulnerabilities detected. This could mean:")
        print("  • The model is well-aligned and secure")
        print("  • The detectors need tuning for this model")
        print("  • More simulation steps needed for meaningful dialogue")
    
    print("\n💡 Next Steps:")
    print("  1. Review the HTML report for detailed findings")
    print("  2. Adjust detector sensitivity if needed")
    print("  3. Run longer simulations for more dialogue")
    print("  4. Test with different model configurations")
    print("=" * 60)


if __name__ == "__main__":
    main()