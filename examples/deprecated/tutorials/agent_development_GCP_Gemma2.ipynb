{
  "cells": [
    {
      "metadata": {
        "id": "yKg27EKlM98K"
      },
      "cell_type": "markdown",
      "source": [
        "# Agent development colab using GCP hosted Gemma 2\n",
        "\n",
        "\n",
        "This notebook presents a prompt engineering view of the Concordia agent development process, making it easier to configure within the Concordia environment. For coding proficient users, a higher level of customization and development will be possible by developing agents directly in the agent factory.\n",
        "\n",
        "\n",
        "To begin, make a copy of this colab and save to google drive. This will impact where the agent file is created that you will eventually submit.\n",
        "\n",
        "\n",
        "Agent Factory: https://github.com/google-deepmind/concordia/tree/main/concordia/factory/agent\n",
        "\n",
        "Additional Agent Tutorials: https://github.com/google-deepmind/concordia/tree/main/examples/tutorials\n",
        "\n",
        "---\n",
        "This tutorial uses GCP hosted Gemma 2. To deply your Gemma2 model on Vertex AI, follow this [doc](https://docs.google.com/document/d/1eT6kNOtE3fuXk91-XvjLjVM9EOZZq_I_vk-XEGN61YA).\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "esFO3miE3s41"
      },
      "cell_type": "markdown",
      "source": [
        "\u003ca href=\"https://colab.research.google.com/github/google-deepmind/concordia/blob/main/examples/deprecated/tutorials/agent_development_GCP_Gemma2.ipynb\" target=\"_parent\"\u003e\u003cimg src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/\u003e\u003c/a\u003e"
      ]
    },
    {
      "metadata": {
        "id": "J2TwJrZ08wXz"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup and imports"
      ]
    },
    {
      "metadata": {
        "cellView": "form",
        "id": "V1BrmvaIDf8y"
      },
      "cell_type": "code",
      "source": [
        "# @title Colab-specific setup (use a CodeSpace to avoid the need for this).\n",
        "try:\n",
        "  %env COLAB_RELEASE_TAG\n",
        "except:\n",
        "  pass  # Not running in colab.\n",
        "else:\n",
        "  %pip install --ignore-requires-python --requirement 'https://raw.githubusercontent.com/google-deepmind/concordia/main/examples/requirements.in' 'git+https://github.com/google-deepmind/concordia.git#egg=gdm-concordia'\n",
        "  %pip list"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "-qLG5ExLqpWa"
      },
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import importlib\n",
        "import numpy as np\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "from concordia.language_model import call_limit_wrapper\n",
        "from concordia.language_model import utils\n",
        "from concordia.utils.deprecated import measurements as measurements_lib\n",
        "import sentence_transformers"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "brdgSD2NuwOQ"
      },
      "cell_type": "markdown",
      "source": []
    },
    {
      "metadata": {
        "id": "brdgSD2NuwOQ"
      },
      "cell_type": "markdown",
      "source": [
        "## Language Model setup"
      ]
    },
    {
      "metadata": {
        "id": "L6YO41FyuwOO"
      },
      "cell_type": "markdown",
      "source": [
        "## Parameters"
      ]
    },
    {
      "metadata": {
        "id": "SxRRMHtemw7W"
      },
      "cell_type": "code",
      "source": [
        "# Select an embedder by specifying one of the sentence transformer embedding\n",
        "# models listed at https://huggingface.co/sentence-transformers.\n",
        "EMBEDDER_NAME = 'all-mpnet-base-v2'\n",
        "# To debug without spending money on API calls, set DISABLE_LANGUAGE_MODEL=True.\n",
        "DISABLE_LANGUAGE_MODEL = False # @param {\"type\":\"boolean\"}"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "I1ZzMoyfcono"
      },
      "cell_type": "code",
      "source": [
        "#@title Imports and initialization\n",
        "\n",
        "# update to the latest Vertex AI api\n",
        "! pip3 install --upgrade --quiet 'google-cloud-aiplatform\u003e=1.64.0'\n",
        "\n",
        "import sentence_transformers\n",
        "from google.colab import auth  # pytype: disable=import-error\n",
        "\n",
        "from concordia.typing import deprecated as typing\n",
        "from concordia.typing.deprecated import entity\n",
        "\n",
        "from concordia.associative_memory.deprecated import associative_memory\n",
        "from concordia.language_model import google_cloud_custom_model\n",
        "from concordia.language_model import language_model\n",
        "\n",
        "# The memory will use a sentence embedder for retrievel, so we download one from\n",
        "# Hugging Face.\n",
        "_embedder_model = sentence_transformers.SentenceTransformer(\n",
        "    'sentence-transformers/all-mpnet-base-v2')\n",
        "embedder = lambda x: _embedder_model.encode(x, show_progress_bar=False)\n",
        "\n",
        "\n",
        "# Language Model - Gemma 2 on Vertex AI\n",
        "\n",
        "endpoint_id = 'YOUR ENDPOINT ID HERE' #@param {type: 'string'}\n",
        "project_id = 'YOUR PROJECT NUMBER HERE' #@param {type: 'string'}\n",
        "region = 'us-central1' #@param {type: 'string'}\n",
        "\n",
        "if not endpoint_id:\n",
        "  raise ValueError('model endpoint id is required')\n",
        "if not project_id:\n",
        "  raise ValueError('A project id is required.')\n",
        "if not region:\n",
        "  raise ValueError('Region information is required.')\n",
        "\n",
        "model = google_cloud_custom_model.VertexAI(endpoint_id=endpoint_id,\n",
        "      project_id=project_id,\n",
        "      location=region)\n",
        "\n",
        "auth.authenticate_user(project_id=project_id)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "sb_VFDtvuwOQ"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup sentence encoder"
      ]
    },
    {
      "metadata": {
        "id": "UE-enMPMuwOQ"
      },
      "cell_type": "code",
      "source": [
        "# @title Setup sentence encoder\n",
        "\n",
        "if DISABLE_LANGUAGE_MODEL:\n",
        "  embedder = lambda x: np.ones(5)\n",
        "else:\n",
        "  _embedder_model = sentence_transformers.SentenceTransformer(\n",
        "      f'sentence-transformers/{EMBEDDER_NAME}')\n",
        "  embedder = lambda x: _embedder_model.encode(x, show_progress_bar=False)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "_1CQOKB0M98K"
      },
      "cell_type": "markdown",
      "source": [
        "# Building an agent"
      ]
    },
    {
      "metadata": {
        "id": "2uUVB1z7M98K"
      },
      "cell_type": "code",
      "source": [
        "%%writefile my_agent.py\n",
        "\n",
        "#@title Imports for agent building\n",
        "import datetime\n",
        "\n",
        "from concordia.agents.deprecated import entity_agent_with_logging\n",
        "from concordia.associative_memory.deprecated import associative_memory\n",
        "from concordia.associative_memory.deprecated import formative_memories\n",
        "from concordia.clocks import game_clock\n",
        "from concordia.components.agent import deprecated as agent_components\n",
        "from concordia.language_model import language_model\n",
        "from concordia.deprecated.memory_bank import legacy_associative_memory\n",
        "from concordia.utils.deprecated import measurements as measurements_lib\n",
        "from concordia.components.agent.deprecated import question_of_recent_memories\n",
        "from typing import Sequence\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "xxdnIvDLM98K"
      },
      "cell_type": "markdown",
      "source": [
        "Agents are composed of components, which are fully customizable. We are going to demonstrate how to design different kinds of agents by using a QuestionOfRecentMemories components. As you get more comfortable with the code, we strongly encourage your to design and build your own agent components.\n",
        "\n",
        "QuestionOfRecentMemories: This type of component proceeds by first retrieving recent memories and then asking a question. For example, the question could be \"What kind of person is {agent_name}?\" or \"What is the rational thing to do next?\" and so on. The answers to these questions will condition the agents action, thereby defining its behavior.\n",
        "\n",
        "\n",
        "Important notes:\n",
        "- All text should refer to the agent in third person, without using \"I\", \"me\", \"mine\" and so on.\n",
        "- A special string {agent_name} will be automatically replaced with the agent's actual name during simulation (e.g. Alice).\n",
        "\n",
        "The agent class will be automatically saved to my_agent.py using iPython magic %%writefile command.\n"
      ]
    },
    {
      "metadata": {
        "id": "P1FQOUHdM98K"
      },
      "cell_type": "code",
      "source": [
        "%%writefile -a my_agent.py\n",
        "\n",
        "#@markdown Each question is a class that inherits from QuestionOfRecentMemories\n",
        "class Question1(question_of_recent_memories.QuestionOfRecentMemories):\n",
        "  \"\"\"This component answers the question 'what kind of person is the agent?'.\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      agent_name:str,\n",
        "      **kwargs,\n",
        "  ):\n",
        "    #@markdown {agent_name} will be automatically replaced with the name of the specific agent\n",
        "    question = 'Given the above, what kind of person is {agent_name}?' #@param {\"type\":\"string\"}\n",
        "    #@markdown The answer will have to start with this prefix\n",
        "    answer_prefix = '{agent_name} is ' #@param {\"type\":\"string\"}\n",
        "    #@markdown Flag that defines whether the answer will be added to memory\n",
        "    add_to_memory = True # @param {\"type\":\"boolean\"}\n",
        "    #@markdown If yes, the memory will start with this tag\n",
        "    memory_tag = '[self reflection]' # @param {\"type\":\"string\"}\n",
        "    question_with_name = question.format(agent_name=agent_name)\n",
        "    super().__init__(\n",
        "        pre_act_key=f'\\nQuestion: {question_with_name}\\nAnswer',\n",
        "        question=question,\n",
        "        answer_prefix=answer_prefix,\n",
        "        add_to_memory=add_to_memory,\n",
        "        memory_tag=memory_tag,\n",
        "        components={},\n",
        "        **kwargs,\n",
        "    )\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "eKbalFVbM98K"
      },
      "cell_type": "code",
      "source": [
        "%%writefile -a my_agent.py\n",
        "\n",
        "#@markdown We can add the value of other components to the context of the question. Notice, how Question2 depends on Observation and ObservationSummary. The names of the classes of the contextualising components have to be passed as \"components\" argument.\n",
        "class Question2(question_of_recent_memories.QuestionOfRecentMemories):\n",
        "  \"\"\"This component answers 'which action is best for achieving my goal?'.\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      agent_name:str,\n",
        "      **kwargs,\n",
        "  ):\n",
        "    question = 'Given the statements above, what kind of situation is {agent_name} in right now?' #@param {\"type\":\"string\"}\n",
        "    answer_prefix = '{agent_name} is currently ' #@param {\"type\":\"string\"}\n",
        "    add_to_memory = False # @param {\"type\":\"boolean\"}\n",
        "    memory_tag = '[situation reflection]' # @param {\"type\":\"string\"}\n",
        "    question_with_name = question.format(agent_name=agent_name)\n",
        "\n",
        "    super().__init__(\n",
        "        pre_act_key=f'\\nQuestion: {question_with_name}\\nAnswer',\n",
        "        question=question,\n",
        "        answer_prefix=answer_prefix,\n",
        "        add_to_memory=add_to_memory,\n",
        "        memory_tag=memory_tag,\n",
        "        #@markdown The key is the name of the component class and the key is the prefix with which it will appear in the context of this component. Be careful if you are going to edit this field, it should be a valid dictionary.\n",
        "        components={'Observation': '\\nObservation', 'ObservationSummary': '\\nSummary of recent observations',}, #@param\n",
        "\n",
        "        **kwargs,\n",
        "    )\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "sEH13Zw3M98K"
      },
      "cell_type": "code",
      "source": [
        "%%writefile -a my_agent.py\n",
        "\n",
        "#@markdown We can also have the questions depend on each other. Here, the answer to Question3 is contextualised by answers to Question1 and Question2\n",
        "class Question3(question_of_recent_memories.QuestionOfRecentMemories):\n",
        "  \"\"\"What would a person like the agent do in a situation like this?\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      agent_name:str,\n",
        "      **kwargs):\n",
        "    question = 'What would a person like {agent_name} do in a situation like this?' #@param {\"type\":\"string\"}\n",
        "    answer_prefix = '{agent_name} would ' #@param {\"type\":\"string\"}\n",
        "    add_to_memory = True # @param {\"type\":\"boolean\"}\n",
        "    memory_tag = '[intent reflection]' # @param {\"type\":\"string\"}\n",
        "\n",
        "    question_with_name = question.format(agent_name=agent_name)\n",
        "\n",
        "    super().__init__(\n",
        "        pre_act_key=f'\\nQuestion: {question_with_name}\\nAnswer',\n",
        "        question=question,\n",
        "        answer_prefix=answer_prefix,\n",
        "        add_to_memory=add_to_memory,\n",
        "        memory_tag=memory_tag,\n",
        "        components={'Question1': f'\\nQuestion: What kind of person is {agent_name}?\\nAnswer', 'Question2': f'\\nQuestion: What kind of situation is {agent_name} in right now?\\nAnswer',}, #@param\n",
        "        **kwargs,\n",
        "    )\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "f8eNNO1rM98K"
      },
      "cell_type": "code",
      "source": [
        "%%writefile -a my_agent.py\n",
        "\n",
        "#@markdown This function creates the components\n",
        "\n",
        "def _make_question_components(\n",
        "    agent_name:str,\n",
        "    measurements: measurements_lib.Measurements,\n",
        "    model: language_model.LanguageModel,\n",
        "    clock: game_clock.MultiIntervalClock,\n",
        ") -\u003e Sequence[question_of_recent_memories.QuestionOfRecentMemories]:\n",
        "\n",
        "  question_1 = Question1(\n",
        "      agent_name=agent_name,\n",
        "      model=model,\n",
        "      logging_channel=measurements.get_channel('Question_1').on_next,\n",
        "  )\n",
        "  question_2 = Question2(\n",
        "      agent_name=agent_name,\n",
        "      model=model,\n",
        "      clock_now=clock.now,\n",
        "      logging_channel=measurements.get_channel('Question_2').on_next,\n",
        "  )\n",
        "  question_3 = Question3(\n",
        "      agent_name=agent_name,\n",
        "      model=model,\n",
        "      clock_now=clock.now,\n",
        "      logging_channel=measurements.get_channel('Question_3').on_next,\n",
        "  )\n",
        "\n",
        "  return (question_1, question_2, question_3)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "2W9WkK1TM98K"
      },
      "cell_type": "code",
      "source": [
        "%%writefile -a my_agent.py\n",
        "\n",
        "def _get_class_name(object_: object) -\u003e str:\n",
        "  return object_.__class__.__name__\n",
        "\n",
        "#@markdown This function builds the agent using the components defined above. It also adds core components that are useful for every agent, like observations, time display, recenet memories.\n",
        "\n",
        "def build_agent(\n",
        "    config: formative_memories.AgentConfig,\n",
        "    model: language_model.LanguageModel,\n",
        "    memory: associative_memory.AssociativeMemory,\n",
        "    clock: game_clock.MultiIntervalClock,\n",
        "    update_time_interval: datetime.timedelta,\n",
        ") -\u003e entity_agent_with_logging.EntityAgentWithLogging:\n",
        "  \"\"\"Build an agent.\n",
        "\n",
        "  Args:\n",
        "    config: The agent config to use.\n",
        "    model: The language model to use.\n",
        "    memory: The agent's memory object.\n",
        "    clock: The clock to use.\n",
        "    update_time_interval: Agent calls update every time this interval passes.\n",
        "\n",
        "  Returns:\n",
        "    An agent.\n",
        "  \"\"\"\n",
        "  del update_time_interval\n",
        "  if not config.extras.get('main_character', False):\n",
        "    raise ValueError(\n",
        "        'This function is meant for a main character '\n",
        "        'but it was called on a supporting character.'\n",
        "    )\n",
        "\n",
        "  agent_name = config.name\n",
        "\n",
        "  raw_memory = legacy_associative_memory.AssociativeMemoryBank(memory)\n",
        "\n",
        "  measurements = measurements_lib.Measurements()\n",
        "  instructions = agent_components.instructions.Instructions(\n",
        "      agent_name=agent_name,\n",
        "      logging_channel=measurements.get_channel('Instructions').on_next,\n",
        "  )\n",
        "\n",
        "  time_display = agent_components.report_function.ReportFunction(\n",
        "      function=clock.current_time_interval_str,\n",
        "      pre_act_key='\\nCurrent time',\n",
        "      logging_channel=measurements.get_channel('TimeDisplay').on_next,\n",
        "  )\n",
        "\n",
        "  observation_label = '\\nObservation'\n",
        "  observation = agent_components.observation.Observation(\n",
        "      clock_now=clock.now,\n",
        "      timeframe=clock.get_step_size(),\n",
        "      pre_act_key=observation_label,\n",
        "      logging_channel=measurements.get_channel('Observation').on_next,\n",
        "  )\n",
        "  observation_summary_label = 'Summary of recent observations'\n",
        "  observation_summary = agent_components.observation.ObservationSummary(\n",
        "      model=model,\n",
        "      clock_now=clock.now,\n",
        "      timeframe_delta_from=datetime.timedelta(hours=4),\n",
        "      timeframe_delta_until=datetime.timedelta(hours=0),\n",
        "      pre_act_key=observation_summary_label,\n",
        "      logging_channel=measurements.get_channel('ObservationSummary').on_next,\n",
        "  )\n",
        "\n",
        "  relevant_memories_label = '\\nRecalled memories and observations'\n",
        "  relevant_memories = agent_components.all_similar_memories.AllSimilarMemories(\n",
        "      model=model,\n",
        "      components={\n",
        "          _get_class_name(observation_summary): observation_summary_label,\n",
        "          _get_class_name(time_display): 'The current date/time is'},\n",
        "      num_memories_to_retrieve=10,\n",
        "      pre_act_key=relevant_memories_label,\n",
        "      logging_channel=measurements.get_channel('AllSimilarMemories').on_next,\n",
        "  )\n",
        "\n",
        "  if config.goal:\n",
        "    goal_label = '\\nOverarching goal'\n",
        "    overarching_goal = agent_components.constant.Constant(\n",
        "        state=config.goal,\n",
        "        pre_act_key=goal_label,\n",
        "        logging_channel=measurements.get_channel(goal_label).on_next)\n",
        "  else:\n",
        "    goal_label = None\n",
        "    overarching_goal = None\n",
        "\n",
        "\n",
        "  question_components = _make_question_components(\n",
        "      agent_name=agent_name,\n",
        "      model=model,\n",
        "      clock=clock,\n",
        "      measurements=measurements\n",
        "  )\n",
        "\n",
        "  core_components = (\n",
        "      instructions,\n",
        "      time_display,\n",
        "      observation,\n",
        "      observation_summary,\n",
        "      relevant_memories,\n",
        "  )\n",
        "\n",
        "  entity_components = core_components + tuple(question_components)\n",
        "  components_of_agent = {\n",
        "      _get_class_name(component): component for component in entity_components\n",
        "  }\n",
        "\n",
        "  components_of_agent[\n",
        "      agent_components.memory_component.DEFAULT_MEMORY_COMPONENT_NAME\n",
        "  ] = agent_components.memory_component.MemoryComponent(raw_memory)\n",
        "  component_order = list(components_of_agent.keys())\n",
        "  if overarching_goal is not None:\n",
        "    components_of_agent[goal_label] = overarching_goal\n",
        "    # Place goal after the instructions.\n",
        "    component_order.insert(1, goal_label)\n",
        "\n",
        "  act_component = agent_components.concat_act_component.ConcatActComponent(\n",
        "      model=model,\n",
        "      clock=clock,\n",
        "      component_order=component_order,\n",
        "      logging_channel=measurements.get_channel('ActComponent').on_next,\n",
        "  )\n",
        "\n",
        "  agent = entity_agent_with_logging.EntityAgentWithLogging(\n",
        "      agent_name=agent_name,\n",
        "      act_component=act_component,\n",
        "      context_components=components_of_agent,\n",
        "      component_logging=measurements,\n",
        "  )\n",
        "\n",
        "  return agent"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "xN_dpScXM98K"
      },
      "cell_type": "code",
      "source": [
        "agent_module = importlib.import_module('my_agent')\n",
        "!zip my_agent.zip my_agent.py\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "FTZjLHpYuwOQ"
      },
      "cell_type": "markdown",
      "source": [
        "# The simulation"
      ]
    },
    {
      "metadata": {
        "id": "bNl5UpuHuwOQ"
      },
      "cell_type": "markdown",
      "source": [
        "## Initialize the simulation"
      ]
    },
    {
      "metadata": {
        "id": "7yBQcLSkjUab"
      },
      "cell_type": "code",
      "source": [
        "# @title Select a scenario\n",
        "from examples.deprecated.modular.scenario import scenarios\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Get all the scenarios\n",
        "all_scenarios = [key for key in scenarios.SCENARIO_CONFIGS.keys()]\n",
        "\n",
        "# Create the dropdown widget\n",
        "dropdown = widgets.Dropdown(\n",
        "    options=all_scenarios,\n",
        "    value='haggling_0',\n",
        "    description='Select a scenario to run on:',\n",
        "    layout={'width': '500px'},  # Adjust the width as needed\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "# Display the widget\n",
        "display.display(dropdown)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "CplEMApbgp7w"
      },
      "cell_type": "code",
      "source": [
        "SCEANRIO_NAME = dropdown.value\n",
        "print(f\"Selected scenario: {SCEANRIO_NAME}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "pCfIjcukuwOQ"
      },
      "cell_type": "code",
      "source": [
        "# @title Initialize the simulation\n",
        "measurements = measurements_lib.Measurements()\n",
        "runnable_simulation = scenarios.build_simulation(\n",
        "    scenarios.SCENARIO_CONFIGS[SCEANRIO_NAME],\n",
        "    model=model,\n",
        "    embedder=embedder,\n",
        "    measurements=measurements,\n",
        "    focal_agent_module=agent_module,\n",
        "    override_agent_model=call_limit_wrapper.CallLimitLanguageModel(model),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "8f0j8s-_uwOR"
      },
      "cell_type": "markdown",
      "source": [
        "## Run the simulation"
      ]
    },
    {
      "metadata": {
        "id": "M4Z1ttTfuwOR"
      },
      "cell_type": "code",
      "source": [
        "# @title Run the simulation\n",
        "simulation_outcome, results_log = runnable_simulation()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "mo9elWtksbkV"
      },
      "cell_type": "code",
      "source": [
        "# @title Calculate and print the score of the agent on the scenario\n",
        "if scenarios.SCENARIO_CONFIGS[SCEANRIO_NAME].focal_is_resident:\n",
        "  total_score = sum(simulation_outcome.resident_scores.values()) / len(simulation_outcome.resident_scores.values())\n",
        "else:\n",
        "  total_score = sum(simulation_outcome.visitor_scores.values()) / len(simulation_outcome.visitor_scores.values())\n",
        "\n",
        "# Score is per-capita reward\n",
        "print('SCORE: ', total_score)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "zzYt04V3cono"
      },
      "cell_type": "markdown",
      "source": [
        "The score above is the score of your agent on the spefic scenario. To evaluate it on all of the scenarios, use the following script:\n",
        "https://github.com/google-deepmind/concordia/blob/main/examples/modular/launch_concordia_challenge_evaluation.py\n"
      ]
    },
    {
      "metadata": {
        "id": "dXb_ay3wLg0k"
      },
      "cell_type": "code",
      "source": [
        "# @title Display the results log\n",
        "display.HTML(results_log)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "iG0axBHXQSqA"
      },
      "cell_type": "code",
      "source": [
        "# @title Summarise the perspective of each player\n",
        "from IPython import display\n",
        "from concordia.utils import html as html_lib\n",
        "\n",
        "player_logs = []\n",
        "player_log_names = []\n",
        "for name, player_memory in (\n",
        "    runnable_simulation.get_all_player_memories().items()):\n",
        "  all_player_mem = list(player_memory.retrieve_recent(k=1000, add_time=True))\n",
        "  all_player_mem = ['Memories:'] + all_player_mem\n",
        "  player_html = html_lib.PythonObjectToHTMLConverter(all_player_mem).convert()\n",
        "  player_logs.append(player_html)\n",
        "  player_log_names.append(f'{name}')\n",
        "\n",
        "player_memories_html = html_lib.combine_html_pages(\n",
        "    player_logs,\n",
        "    player_log_names,\n",
        "    summary='',\n",
        "    title='Player Memories',\n",
        ")\n",
        "\n",
        "player_memories_html = html_lib.finalise_html(player_memories_html)\n",
        "display.HTML(player_memories_html)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "oaiIye0KuwOR"
      },
      "cell_type": "markdown",
      "source": [
        "## Save the results log"
      ]
    },
    {
      "metadata": {
        "id": "sDGkKpsruwOR"
      },
      "cell_type": "code",
      "source": [
        "# @title Write the results log as an HTML file in the current working directory.\n",
        "filename = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S') + '.html'\n",
        "file_handle = open(filename, 'a')\n",
        "file_handle.write(results_log)\n",
        "file_handle.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "x5EtZPP5gp7w"
      },
      "cell_type": "markdown",
      "source": [
        "Now that you have successfully built an agent and have a greater understanding of agent components, we highly recommend exploring on your own. Remember, agent components are fully customizable. Check out the tutorial on components to learn more: https://github.com/google-deepmind/concordia/blob/main/examples/tutorials/agent_components_tutorial.ipynb\n",
        "\n",
        "To work with a more flexible .py file, navigate to concordia/factory/agent and duplicate the basic_agent.py file to get started or just copy the my_agent.py that was created by this colab, which is a valid agent factory.\n",
        "\n",
        "Agent factory: https://github.com/google-deepmind/concordia/tree/main/concordia/factory/agent\n",
        "\n",
        "\n",
        "Agentâ€™s that are in the factory can be tested on the full set of scenarios by running the following script\n",
        "\n",
        "Script for full evaluation across substrates: https://github.com/google-deepmind/concordia/blob/main/examples/modular/launch_concordia_challenge_evaluation.py\n",
        "\n",
        "More Tutorials: https://github.com/google-deepmind/concordia/tree/main/examples/tutorials\n"
      ]
    },
    {
      "metadata": {
        "id": "qWDqd4ByzSsT"
      },
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Copyright 2023 DeepMind Technologies Limited.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
