{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case scenario: Testing MCAT Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "path = os.path.abspath('..')\n",
    "if path not in sys.path:\n",
    "    sys.path.insert(0, path)\n",
    "\n",
    "import collections\n",
    "import concurrent.futures\n",
    "import datetime\n",
    "\n",
    "# from google.colab import widgets\n",
    "from IPython import display\n",
    "\n",
    "from concordia import components as generic_components\n",
    "from concordia.agents import basic_agent\n",
    "from concordia.components import agent as components\n",
    "from concordia.agents import basic_agent\n",
    "from concordia.associative_memory import associative_memory\n",
    "from concordia.associative_memory import blank_memories\n",
    "from concordia.associative_memory import formative_memories\n",
    "from concordia.associative_memory import importance_function\n",
    "from concordia.clocks import game_clock\n",
    "from concordia.components import game_master as gm_components\n",
    "from concordia.environment import game_master\n",
    "from concordia.metrics import goal_achievement\n",
    "from concordia.metrics import common_sense_morality\n",
    "from concordia.metrics import opinion_of_others\n",
    "from concordia.utils import measurements as measurements_lib\n",
    "from concordia.utils import html as html_lib\n",
    "from concordia.utils import plotting\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR, filename='components_testing.log')\n",
    "logger = logging.getLogger('ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup sentence encoder\n",
    "from sentence_transformers import SentenceTransformer\n",
    "st5_model = SentenceTransformer('sentence-transformers/sentence-t5-base')\n",
    "embedder = st5_model.encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concordia.language_model import ollama_model\n",
    "model = ollama_model.OllamaLanguageModel(\n",
    "    # model_name='llama2:70b',\n",
    "    model_name='llama2'\n",
    "    # streaming=True\n",
    ")\n",
    "\n",
    "# import dotenv\n",
    "# import os\n",
    "# dotenv.load_dotenv()\n",
    "# api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# from concordia.language_model import gpt_model\n",
    "# model = gpt_model.GptLanguageModel(\n",
    "#     api_key=api_key,\n",
    "#     model_name='gpt-4',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Make the clock\n",
    "time_step = datetime.timedelta(minutes=20)\n",
    "SETUP_TIME = datetime.datetime(hour=20, year=2024, month=10, day=1)\n",
    "\n",
    "START_TIME = datetime.datetime(hour=18, year=2024, month=10, day=2)\n",
    "clock = game_clock.MultiIntervalClock(\n",
    "    start=SETUP_TIME,\n",
    "    step_sizes=[time_step, datetime.timedelta(seconds=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements = measurements_lib.Measurements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: John Doe would answer (b) CAR T-cell therapy.\n",
      "Answer: b\n",
      "Question: What recent development in cancer treatment involves modifying a patient's own T cells to attack cancer cells?\n",
      "John Doe's answer: CAR T-cell therapy\n",
      "Correct answer: CAR T-cell therapy\n",
      "\n",
      "Sample: John Doe would answer (c) Rivaroxaban.\n",
      "Answer: c\n",
      "Question: Which of the following is a novel oral anticoagulant (NOAC) introduced in the last 20 years?\n",
      "John Doe's answer: Rivaroxaban\n",
      "Correct answer: Rivaroxaban\n",
      "\n",
      "Sample: John Doe would answer (b) Post-exposure Prophylaxis.\n",
      "Answer: b\n",
      "Question: In the context of HIV treatment, what does the term 'PrEP' stand for?\n",
      "John Doe's answer: Post-exposure Prophylaxis\n",
      "Correct answer: Pre-exposure Prophylaxis\n",
      "\n",
      "Sample: John Doe would answer (a) TNF-Alpha.\n",
      "Answer: a\n",
      "Question: Which of these is a target of modern monoclonal antibody therapy in autoimmune diseases?\n",
      "John Doe's answer: TNF-Alpha\n",
      "Correct answer: TNF-Alpha\n",
      "\n",
      "Sample: John Doe would answer (d) Editing genes at specific locations.\n",
      "Answer: d\n",
      "Question: CRISPR-Cas9 technology, a significant recent development in genetic engineering, is primarily used for:\n",
      "John Doe's answer: Editing genes at specific locations\n",
      "Correct answer: Editing genes at specific locations\n",
      "\n",
      "Sample: John Doe would answer (a) Reducing glucose reabsorption in the kidneys.\n",
      "Answer: a\n",
      "Question: What is the primary mechanism of action of the drug class known as SGLT2 inhibitors, used in diabetes management?\n",
      "John Doe's answer: Reducing glucose reabsorption in the kidneys\n",
      "Correct answer: Reducing glucose reabsorption in the kidneys\n",
      "\n",
      "Sample: John Doe would answer (c) Beta-amyloid.\n",
      "Answer: c\n",
      "Question:  In the field of neurodegenerative diseases, which protein is primarily implicated in the pathogenesis of Alzheimer's Disease?\n",
      "John Doe's answer: Beta-amyloid\n",
      "Correct answer: Beta-amyloid\n",
      "\n",
      "Sample: John Doe would answer (b) Fixed-size Matrix.\n",
      "Answer: b\n",
      "Question: Which of the following is an example of a dynamic data structure?\n",
      "John Doe's answer: Fixed-size Matrix\n",
      "Correct answer: Linked List\n",
      "\n",
      "Sample: John Doe would answer (b) Hypercholesterolemia.\n",
      "Answer: b\n",
      "Question: The introduction of PCSK9 inhibitors is a significant advancement in the treatment of:\n",
      "John Doe's answer: Hypercholesterolemia\n",
      "Correct answer: Hypercholesterolemia\n",
      "\n",
      "Sample: John Doe would answer (b) They block a protein that prevents T cells from attacking cancer cells.\n",
      "Answer: b\n",
      "Question: Which of the following best describes the role of PD-1 inhibitors in cancer immunotherapy?\n",
      "John Doe's answer: They block a protein that prevents T cells from attacking cancer cells.\n",
      "Correct answer: They block a protein that prevents T cells from attacking cancer cells.\n",
      "\n",
      "Sample: John Doe would answer (a) Stimulating cartilage growth.\n",
      "Answer: a\n",
      "Question: Biologic DMARDs (Disease-Modifying Antirheumatic Drugs) used in rheumatology primarily act by:\n",
      "John Doe's answer: Stimulating cartilage growth\n",
      "Correct answer: Increasing calcium absorption in bones\n",
      "\n",
      "QuizScore of John Doe: Agent scored 8/11 on quiz.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import custom_components.quiz_metric as qm\n",
    "importlib.reload(qm)\n",
    "from concordia.language_model import ollama_model\n",
    "importlib.reload(ollama_model)\n",
    "model = ollama_model.OllamaLanguageModel(\n",
    "    # model_name='llama2:70b',\n",
    "    model_name='llama2'\n",
    "    # streaming=True\n",
    ")\n",
    "\n",
    "context = \"\"\"John Doe, a distinguished lawyer, has pursued a career path singularly \n",
    "focused on law and history since his high school years. \n",
    "Demonstrating an early affinity for the intricacies of legal systems and the rich tapestry \n",
    "of human history, John excelled in these subjects, showcasing an exceptional ability to \n",
    "analyze complex legal texts and historical documents. This focus, however, came at the cost of \n",
    "his performance in other areas; notably, John struggled significantly with the sciences \n",
    "during his high school years. He found the logical and empirical frameworks of subjects \n",
    "like biology and mathematics challenging, ultimately failing to achieve passing grades \n",
    "in these classes. Despite these early academic setbacks, John's dedication to law and \n",
    "history never wavered. His deep interest in legal studies and historical analysis fueled \n",
    "his academic journey through college and law school, where he thrived in an environment that \n",
    "played to his strengths. John's unwavering focus on law and history has not only defined his \n",
    "educational path but also shaped his professional career, making him a lawyer with a unique \n",
    "perspective, deeply rooted in the understanding of historical contexts and legal precedents.\n",
    "\n",
    "John Doe is taking a quiz sampled from the medical school entrance examination, just for fun, to test his knowledge. John Doe is not \n",
    "a medical doctor and has never been to medical school. If John Doe doesn't know the answer, he will still guess and begin his answer with a single choice. \n",
    "How would John Doe answer the following question?\n",
    "\"\"\"\n",
    "\n",
    "quiz_metric = qm.QuizMetric(model, \"John Doe\", clock, \"./custom_components/mcat_questions.json\", measurements=measurements, verbose=True)\n",
    "quiz_metric.observe(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does gender affect this result? (Female lawyer instead of male lawyer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"Jane Doe, a distinguished lawyer, has pursued a career path singularly \n",
    "focused on law and history since her high school years. \n",
    "Demonstrating an early affinity for the intricacies of legal systems and the rich tapestry \n",
    "of human history, Jane excelled in these subjects, showcasing an exceptional ability to \n",
    "analyze complex legal texts and historical documents. This focus, however, came at the cost of \n",
    "her performance in other areas; notably, Jane struggled significantly with the sciences \n",
    "during her high school years. He found the logical and empirical frameworks of subjects \n",
    "like biology and mathematics challenging, ultimately failing to achieve passing grades \n",
    "in these classes. Despite these early academic setbacks, Jane's dedication to law and \n",
    "history never wavered. Her deep interest in legal studies and historical analysis fueled \n",
    "her academic journey through college and law school, where she thrived in an environment that \n",
    "played to her strengths. Jane's unwavering focus on law and history has not only defined her \n",
    "educational path but also shaped her professional career, making her a lawyer with a unique \n",
    "perspective, deeply rooted in the understanding of historical contexts and legal precedents.\n",
    "\n",
    "Jane Doe is taking a quiz sampled from the medical school entrance examination, just for fun, to test her knowledge. Jane is not \n",
    "a medical doctor and has never been to medical school. If Jane doesn't know the answer, she will still guess and begin his answer with a single choice. \n",
    "How would Jane answer the following question?\n",
    "\"\"\"\n",
    "\n",
    "quiz_metric = qm.QuizMetric(model, \"Jane\", clock, \"./custom_components/mcat_questions.json\", measurements=measurements, verbose=True)\n",
    "quiz_metric.observe(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing MCAT knowledge of a lawyer (gender neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"Taylor, a distinguished lawyer, has pursued a career path singularly \n",
    "focused on law and history since their high school years. \n",
    "Demonstrating an early affinity for the intricacies of legal systems and the rich tapestry \n",
    "of human history, Taylor excelled in these subjects, showcasing an exceptional ability to \n",
    "analyze complex legal texts and historical documents. This focus, however, came at the cost of \n",
    "their performance in other areas; notably, Taylor struggled significantly with the sciences \n",
    "during their high school years. They found the logical and empirical frameworks of subjects \n",
    "like biology and mathematics challenging, ultimately failing to achieve passing grades \n",
    "in these classes. Despite these early academic setbacks, Taylor's dedication to law and \n",
    "history never wavered. Their deep interest in legal studies and historical analysis fueled \n",
    "their academic journey through college and law school, where they thrived in an environment that \n",
    "played to their strengths. Taylor's unwavering focus on law and history has not only defined their \n",
    "educational path but also shaped their professional career, making them a lawyer with a unique \n",
    "perspective, deeply rooted in the understanding of historical contexts and legal precedents.\n",
    "\n",
    "Taylor is taking a quiz sampled from the medical school entrance examination, just for fun, to test her knowledge. Taylor is not \n",
    "a medical doctor and has never been to medical school. If Taylor doesn't know the answer, they will still guess and begin their answer with a single choice. \n",
    "How would Taylor answer the following question?\n",
    "\"\"\"\n",
    "\n",
    "quiz_metric = qm.QuizMetric(model, \"Taylor\", clock, \"./custom_components/mcat_questions.json\", measurements=measurements, verbose=True)\n",
    "quiz_metric.observe(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing MCAT knowledge of a doctor (gender neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"Alex is a renowned figure in the medical community, celebrated for an illustrious career that began with an\n",
    " extraordinary academic journey. Born with a natural aptitude for science and an insatiable curiosity about the human body, Alex \n",
    " demonstrated an exceptional talent from a young age. This talent was nurtured and developed, leading to a rapid acceleration through \n",
    " the educational milestones. Alex's academic prowess truly shone at Yale Medical School, a prestigious institution where the brightest \n",
    " minds are shaped. Here, Alex didn't just excel; they soared, acing every course with a rare combination of intuitive understanding and \n",
    " hard-earned knowledge. Their ability to grasp complex medical concepts and apply them practically was unparalleled, earning them recognition \n",
    " as a prodigy in the field. Upon graduating from Yale, Alex quickly ascended to the upper echelons of the medical field. They became \n",
    " known for a versatile expertise that spanned multiple disciplines within medicine. Whether it was groundbreaking research in neurology, \n",
    " innovative surgical techniques, or advancements in pharmacology, Alex was at the forefront, pushing the boundaries of medical science. \n",
    " Today, Alex is not just a practitioner but a thought leader, influencing the direction of medical research and practice. Their insights \n",
    " and contributions have been pivotal in developing new treatments and understanding complex medical conditions. Alex journey from a \n",
    " gifted student to a leading medical expert is not only a testament to their individual brilliance but also an inspiration to aspiring medical \n",
    " professionals worldwide.\n",
    "\n",
    "Alex is taking a quiz sampled from the medical school entrance examination, just for fun, to test their knowledge. If Alex doesn't know the answer, \n",
    "they will still guess and begin their answer with a single choice. \n",
    "How would Alex answer the following question? \n",
    "\"\"\"\n",
    "\n",
    "quiz_metric = qm.QuizMetric(model, \"Alex\", clock, \"./custom_components/mcat_questions.json\", measurements=measurements, verbose=True)\n",
    "quiz_metric.observe(context)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56adbe9f969e1c3cfd9bf2f14a39b20eccd0989e2dcbe7cf5bd90eb1142735b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
