# -*- coding: utf-8 -*-
"""agent_development_GCP_Gemma2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/google-deepmind/concordia/blob/main/examples/tutorials/agent_development_GCP_Gemma2.ipynb

# Agent development colab using GCP hosted Gemma 2


This notebook presents a prompt engineering view of the Concordia agent development process, making it easier to configure within the Concordia environment. For coding proficient users, a higher level of customization and development will be possible by developing agents directly in the agent factory.


To begin, make a copy of this colab and save to google drive. This will impact where the agent file is created that you will eventually submit.


Agent Factory: https://github.com/google-deepmind/concordia/tree/main/concordia/factory/agent

Additional Agent Tutorials: https://github.com/google-deepmind/concordia/tree/main/examples/tutorials

---
This tutorial uses GCP hosted Gemma 2. To deply your Gemma2 model on Vertex AI, follow this [doc](https://docs.google.com/document/d/1eT6kNOtE3fuXk91-XvjLjVM9EOZZq_I_vk-XEGN61YA).

<a href="https://colab.research.google.com/github/google-deepmind/concordia/blob/main/examples/tutorials/agent_development_GCP_Gemma2.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

## Setup and imports
"""

# Commented out IPython magic to ensure Python compatibility.
# @title Colab-specific setup (use a CodeSpace to avoid the need for this).

import sys
project_root = '/home/xinyuan/Documents/concordia'
sys.path.append(project_root)
path_to_concordia = sys.path[-1]
print(f"SYSTEM PATH LAST: {path_to_concordia}")

import datetime
import importlib
import numpy as np

from IPython import display

from concordia.language_model import call_limit_wrapper
from concordia.language_model import utils
from concordia.utils import measurements as measurements_lib
import sentence_transformers

"""## Language Model setup

## Parameters
"""

# Select an embedder by specifying one of the sentence transformer embedding
# models listed at https://huggingface.co/sentence-transformers.
EMBEDDER_NAME = 'all-mpnet-base-v2'
# To debug without spending money on API calls, set DISABLE_LANGUAGE_MODEL=True.
DISABLE_LANGUAGE_MODEL = False # @param {"type":"boolean"}

import sentence_transformers

from concordia import typing
from concordia.typing import entity

from concordia.associative_memory import associative_memory
from concordia.language_model import google_cloud_custom_model
from concordia.language_model import language_model

# The memory will use a sentence embedder for retrievel, so we download one from
# Hugging Face.
_embedder_model = sentence_transformers.SentenceTransformer(
    'sentence-transformers/all-mpnet-base-v2')
embedder = lambda x: _embedder_model.encode(x, show_progress_bar=False)

# Language Model - Gemma 2 on Vertex AI

endpoint_id = '8851667837433937920' #@param {type: 'string'}
project_id = '706681395781' #@param {type: 'string'}
region = 'us-central1' #@param {type: 'string'}

if not endpoint_id:
  raise ValueError('model endpoint id is required')
if not project_id:
  raise ValueError('A project id is required.')
if not region:
  raise ValueError('Region information is required.')

model = google_cloud_custom_model.VertexAI(endpoint_id=endpoint_id,
      project_id=project_id,
      location=region)

"""## Setup sentence encoder"""

# @title Setup sentence encoder

if DISABLE_LANGUAGE_MODEL:
  embedder = lambda x: np.ones(5)
else:
  _embedder_model = sentence_transformers.SentenceTransformer(
      f'sentence-transformers/{EMBEDDER_NAME}')
  embedder = lambda x: _embedder_model.encode(x, show_progress_bar=False)

"""## Select Agent"""
args = sys.argv[1:]
agent_name = args[0] if len(args) > 0 else 'my_agent'
print(f"AGENT: {agent_name}")

IMPORT_AGENT_BASE_DIR = 'concordia.factory.agent'
agent_module = importlib.import_module(
    f'{IMPORT_AGENT_BASE_DIR}.{agent_name}'
)

"""# The simulation

## Initialize the simulation
"""

# @title Select a scenario
from examples.modular.scenario import scenarios

# Get all the scenarios
all_scenarios = [key for key in scenarios.SCENARIO_CONFIGS.keys()]
print("List of Scenarios:")
for key in scenarios.SCENARIO_CONFIGS.keys():
  print(f"- {key}")

SCEANRIO_NAME = 'haggling_0'
# SCEANRIO_NAME = 'labor_collective_action__fixed_rule_boss_0'
# SCEANRIO_NAME = 'pub_coordination_0'
print(f"Selected Scenario: {SCEANRIO_NAME}")

# @title Initialize the simulation
measurements = measurements_lib.Measurements()
runnable_simulation = scenarios.build_simulation(
    scenarios.SCENARIO_CONFIGS[SCEANRIO_NAME],
    model=model,
    embedder=embedder,
    measurements=measurements,
    focal_agent_module=agent_module,
    override_agent_model=call_limit_wrapper.CallLimitLanguageModel(model),
    seed = 1, # random seed for GM
)

"""## Run the simulation"""

# @title Run the simulation
simulation_outcome, results_log = runnable_simulation()


# @title Calculate and print the score of the agent on the scenario
if scenarios.SCENARIO_CONFIGS[SCEANRIO_NAME].focal_is_resident:
  total_score = sum(simulation_outcome.resident_scores.values()) / len(simulation_outcome.resident_scores.values())
else:
  total_score = sum(simulation_outcome.visitor_scores.values()) / len(simulation_outcome.visitor_scores.values())

# Score is per-capita reward
print('SCORE: ', total_score)

# @titel Write the score in a text file
log_prefix = path_to_concordia + '/data/'
time_now = datetime.datetime.now().strftime('%d %H:%M')

filename = log_prefix + 'score.txt'
title = f'[{SCEANRIO_NAME}] {agent_name} {time_now}\n'

file_handle = open(filename, 'a')
file_handle.write(title)
file_handle.write(f">>> {total_score}\n")
file_handle.write('-----\n')
file_handle.close()

"""The score above is the score of your agent on the spefic scenario. To evaluate it on all of the scenarios, use the following script:
https://github.com/google-deepmind/concordia/blob/main/examples/modular/launch_concordia_challenge_evaluation.py

"""

# @title Display the results log
display.HTML(results_log)

# @title Summarise the perspective of each player
from IPython import display
from concordia.utils import html as html_lib

player_logs = []
player_log_names = []
for name, player_memory in (
    runnable_simulation.get_all_player_memories().items()):
  all_player_mem = list(player_memory.retrieve_recent(k=1000, add_time=True))
  all_player_mem = ['Memories:'] + all_player_mem
  player_html = html_lib.PythonObjectToHTMLConverter(all_player_mem).convert()
  player_logs.append(player_html)
  player_log_names.append(f'{name}')

player_memories_html = html_lib.combine_html_pages(
    player_logs,
    player_log_names,
    summary='',
    title='Player Memories',
)

player_memories_html = html_lib.finalise_html(player_memories_html)
display.HTML(player_memories_html)

"""## Save the results log"""

# @title Write the results log as an HTML file in the current working directory.
filename = f'{log_prefix}{time_now} {SCEANRIO_NAME} {agent_name}.html'
file_handle = open(filename, 'a')
file_handle.write(results_log)
file_handle.close()

"""Now that you have successfully built an agent and have a greater understanding of agent components, we highly recommend exploring on your own. Remember, agent components are fully customizable. Check out the tutorial on components to learn more: https://github.com/google-deepmind/concordia/blob/main/examples/tutorials/agent_components_tutorial.ipynb

To work with a more flexible .py file, navigate to concordia/factory/agent and duplicate the basic_agent.py file to get started or just copy the my_agent.py that was created by this colab, which is a valid agent factory.

Agent factory: https://github.com/google-deepmind/concordia/tree/main/concordia/factory/agent


Agentâ€™s that are in the factory can be tested on the full set of scenarios by running the following script

Script for full evaluation across substrates: https://github.com/google-deepmind/concordia/blob/main/examples/modular/launch_concordia_challenge_evaluation.py

More Tutorials: https://github.com/google-deepmind/concordia/tree/main/examples/tutorials

```
Copyright 2023 DeepMind Technologies Limited.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    https://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
```
"""
