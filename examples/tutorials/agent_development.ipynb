{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKg27EKlM98K"
      },
      "source": [
        "# Agent development colab\n",
        "\n",
        "\n",
        "This notebook presents a prompt engineering view of the Concordia agent development process, making it easier to configure within the Concordia environment. For coding proficient users, a higher level of customization and development will be possible by developing agents directly in the agent factory.\n",
        "\n",
        "\n",
        "To begin, make a copy of this colab and save to google drive. This will impact where the agent file is created that you will eventually submit.\n",
        "\n",
        "\n",
        "Agent Factory: https://github.com/google-deepmind/concordia/tree/main/concordia/factory/agent\n",
        "\n",
        "Additional Agent Tutorials: https://github.com/google-deepmind/concordia/tree/main/examples/tutorials\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esFO3miE3s41"
      },
      "source": [
        "\u003ca href=\"https://colab.research.google.com/github/google-deepmind/concordia/blob/main/examples/tutorials/agent_development.ipynb\" target=\"_parent\"\u003e\u003cimg src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/\u003e\u003c/a\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2TwJrZ08wXz"
      },
      "source": [
        "## Setup and imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "V1BrmvaIDf8y"
      },
      "outputs": [],
      "source": [
        "# @title Colab-specific setup (use a CodeSpace to avoid the need for this).\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
        "  project_root = '/content/concordia'\n",
        "\n",
        "  # Download the source code.\n",
        "  if not os.path.exists(project_root):\n",
        "    !git clone https://github.com/google-deepmind/concordia.git\n",
        "\n",
        "  # Install concordia and dependencies.\n",
        "  %pip install --ignore-requires-python -e /content/concordia\n",
        "  %pip install -r /content/concordia/examples/requirements.txt\n"
      ]
    },
    {
      "metadata": {
        "id": "TNRcsA1HHYwB"
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
        "  project_root = '/content/concordia'\n",
        "\n",
        "  # Add root to python path.\n",
        "  if project_root not in sys.path:\n",
        "    sys.path.append(project_root)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qLG5ExLqpWa"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import importlib\n",
        "import numpy as np\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "from concordia.language_model import call_limit_wrapper\n",
        "from concordia.language_model import utils\n",
        "from concordia.utils import measurements as measurements_lib\n",
        "import sentence_transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brdgSD2NuwOQ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brdgSD2NuwOQ"
      },
      "source": [
        "## Language Model setup"
      ]
    },
    {
      "metadata": {
        "id": "mL0m8q7jYvo8"
      },
      "cell_type": "markdown",
      "source": [
        "# API KEY\n",
        "\n",
        "Codestral / Mistral / OpenAI\n",
        "\n",
        "Links to where to generate API Key\n",
        "\n",
        "Together AI = https://api.together.xyz/settings/api-keys \n",
        "\n",
        "Mistral = https://console.mistral.ai/api-keys/\n",
        "\n",
        "OpenAI = https://platform.openai.com/settings/profile?tab=api-keys (Profile -\u003e API Keys) Note: GPT-4o models can be unwilling to participate in game structures resulting in worse performance. \n",
        "\n",
        "\n",
        "Using API_TYPE='together_ai', MODEL_NAME='google/gemma-2-9b-it' is advised.\n",
        "\n",
        "\n",
        "## Disable language model \n",
        "\n",
        "Select ‘Disable language model’ when testing code functionality to prevent unnecessary cost and to save time. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6YO41FyuwOO"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "metadata": {
        "id": "I1ZzMoyfcono"
      },
      "cell_type": "code",
      "source": [
        "# @title Parameters (edit this cell)\n",
        "\n",
        "# Pick API_TYPE from concordia/language_model/utils.py, e.g. mistral.\n",
        "API_TYPE = 'together_ai'\n",
        "# Add your API key here or alternatively, leave this as None to get it from an\n",
        "# environment variable.\n",
        "API_KEY = 'YOUR API KEY HERE' # @param {\"type\":\"string\"}\n",
        "# Pick  a specific model e.g. gpt-4o if API_TYPE is openai, codestral-latest if\n",
        "# API_TYPE is mistral. See the corresponding wrapper in concordia/language_model\n",
        "# for links to the websites where the model names are listed for each API_TYPE.\n",
        "MODEL_NAME = 'google/gemma-2-9b-it'\n",
        "# Select an embedder by specifying one of the sentence transformer embedding\n",
        "# models listed at https://huggingface.co/sentence-transformers.\n",
        "EMBEDDER_NAME = 'all-mpnet-base-v2'\n",
        "# To debug without spending money on API calls, set DISABLE_LANGUAGE_MODEL=True.\n",
        "DISABLE_LANGUAGE_MODEL = False # @param {\"type\":\"boolean\"}"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ez6153pSuwOQ"
      },
      "outputs": [],
      "source": [
        "# @title Language Model setup\n",
        "\n",
        "model = utils.language_model_setup(\n",
        "    api_type=API_TYPE,\n",
        "    model_name=MODEL_NAME,\n",
        "    api_key=API_KEY,\n",
        "    disable_language_model=DISABLE_LANGUAGE_MODEL,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb_VFDtvuwOQ"
      },
      "source": [
        "## Setup sentence encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UE-enMPMuwOQ"
      },
      "outputs": [],
      "source": [
        "# @title Setup sentence encoder\n",
        "\n",
        "if DISABLE_LANGUAGE_MODEL:\n",
        "  embedder = lambda x: np.ones(5)\n",
        "else:\n",
        "  _embedder_model = sentence_transformers.SentenceTransformer(\n",
        "      f'sentence-transformers/{EMBEDDER_NAME}')\n",
        "  embedder = lambda x: _embedder_model.encode(x, show_progress_bar=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1CQOKB0M98K"
      },
      "source": [
        "# Building an agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uUVB1z7M98K"
      },
      "outputs": [],
      "source": [
        "%%writefile my_agent.py\n",
        "\n",
        "#@title Imports for agent building\n",
        "import datetime\n",
        "\n",
        "from concordia.agents import entity_agent_with_logging\n",
        "from concordia.associative_memory import associative_memory\n",
        "from concordia.associative_memory import formative_memories\n",
        "from concordia.clocks import game_clock\n",
        "from concordia.components import agent as agent_components\n",
        "from concordia.language_model import language_model\n",
        "from concordia.memory_bank import legacy_associative_memory\n",
        "from concordia.utils import measurements as measurements_lib\n",
        "from concordia.components.agent import question_of_recent_memories\n",
        "from typing import Sequence\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxdnIvDLM98K"
      },
      "source": [
        "Agents are composed of components, which are fully customizable. We are going to demonstrate how to design different kinds of agents by using a QuestionOfRecentMemories components. As you get more comfortable with the code, we strongly encourage your to design and build your own agent components.\n",
        "\n",
        "QuestionOfRecentMemories: This type of component proceeds by first retrieving recent memories and then asking a question. For example, the question could be \"What kind of person is {agent_name}?\" or \"What is the rational thing to do next?\" and so on. The answers to these questions will condition the agents action, thereby defining its behavior.\n",
        "\n",
        "\n",
        "Important notes:\n",
        "- All text should refer to the agent in third person, without using \"I\", \"me\", \"mine\" and so on.\n",
        "- A special string {agent_name} will be automatically replaced with the agent's actual name during simulation (e.g. Alice).\n",
        "\n",
        "The agent class will be automatically saved to my_agent.py using iPython magic %%writefile command.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1FQOUHdM98K"
      },
      "outputs": [],
      "source": [
        "%%writefile -a my_agent.py\n",
        "\n",
        "#@markdown Each question is a class that inherits from QuestionOfRecentMemories\n",
        "class Question1(question_of_recent_memories.QuestionOfRecentMemories):\n",
        "  \"\"\"This component answers the question 'what kind of person is the agent?'.\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      agent_name:str,\n",
        "      **kwargs,\n",
        "  ):\n",
        "    #@markdown {agent_name} will be automatically replaced with the name of the specific agent\n",
        "    question = 'Given the above, what kind of person is {agent_name}?' #@param {\"type\":\"string\"}\n",
        "    #@markdown The answer will have to start with this prefix\n",
        "    answer_prefix = '{agent_name} is ' #@param {\"type\":\"string\"}\n",
        "    #@markdown Flag that defines whether the answer will be added to memory\n",
        "    add_to_memory = True # @param {\"type\":\"boolean\"}\n",
        "    #@markdown If yes, the memory will start with this tag\n",
        "    memory_tag = '[self reflection]' # @param {\"type\":\"string\"}\n",
        "    question_with_name = question.format(agent_name=agent_name)\n",
        "    super().__init__(\n",
        "        pre_act_key=f'\\nQuestion: {question_with_name}\\nAnswer',\n",
        "        question=question,\n",
        "        answer_prefix=answer_prefix,\n",
        "        add_to_memory=add_to_memory,\n",
        "        memory_tag=memory_tag,\n",
        "        components={},\n",
        "        **kwargs,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKbalFVbM98K"
      },
      "outputs": [],
      "source": [
        "%%writefile -a my_agent.py\n",
        "\n",
        "#@markdown We can add the value of other components to the context of the question. Notice, how Question2 depends on Observation and ObservationSummary. The names of the classes of the contextualising components have to be passed as \"components\" argument.\n",
        "class Question2(question_of_recent_memories.QuestionOfRecentMemories):\n",
        "  \"\"\"This component answers 'which action is best for achieving my goal?'.\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      agent_name:str,\n",
        "      **kwargs,\n",
        "  ):\n",
        "    question = 'Given the statements above, what kind of situation is {agent_name} in right now?' #@param {\"type\":\"string\"}\n",
        "    answer_prefix = '{agent_name} is currently ' #@param {\"type\":\"string\"}\n",
        "    add_to_memory = False # @param {\"type\":\"boolean\"}\n",
        "    memory_tag = '[situation reflection]' # @param {\"type\":\"string\"}\n",
        "    question_with_name = question.format(agent_name=agent_name)\n",
        "\n",
        "    super().__init__(\n",
        "        pre_act_key=f'\\nQuestion: {question_with_name}\\nAnswer',\n",
        "        question=question,\n",
        "        answer_prefix=answer_prefix,\n",
        "        add_to_memory=add_to_memory,\n",
        "        memory_tag=memory_tag,\n",
        "        #@markdown The key is the name of the component class and the key is the prefix with which it will appear in the context of this component. Be careful if you are going to edit this field, it should be a valid dictionary.\n",
        "        components={'Observation': '\\nObservation', 'ObservationSummary': '\\nSummary of recent observations',}, #@param\n",
        "\n",
        "        **kwargs,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEH13Zw3M98K"
      },
      "outputs": [],
      "source": [
        "%%writefile -a my_agent.py\n",
        "\n",
        "#@markdown We can also have the questions depend on each other. Here, the answer to Question3 is contextualised by answers to Question1 and Question2\n",
        "class Question3(question_of_recent_memories.QuestionOfRecentMemories):\n",
        "  \"\"\"What would a person like the agent do in a situation like this?\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      agent_name:str,\n",
        "      **kwargs):\n",
        "    question = 'What would a person like {agent_name} do in a situation like this?' #@param {\"type\":\"string\"}\n",
        "    answer_prefix = '{agent_name} would ' #@param {\"type\":\"string\"}\n",
        "    add_to_memory = True # @param {\"type\":\"boolean\"}\n",
        "    memory_tag = '[intent reflection]' # @param {\"type\":\"string\"}\n",
        "\n",
        "    question_with_name = question.format(agent_name=agent_name)\n",
        "\n",
        "    super().__init__(\n",
        "        pre_act_key=f'\\nQuestion: {question_with_name}\\nAnswer',\n",
        "        question=question,\n",
        "        answer_prefix=answer_prefix,\n",
        "        add_to_memory=add_to_memory,\n",
        "        memory_tag=memory_tag,\n",
        "        components={'Question1': f'\\nQuestion: What kind of person is {agent_name}?\\nAnswer', 'Question2': f'\\nQuestion: What kind of situation is {agent_name} in right now?\\nAnswer',}, #@param\n",
        "        **kwargs,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8eNNO1rM98K"
      },
      "outputs": [],
      "source": [
        "%%writefile -a my_agent.py\n",
        "\n",
        "#@markdown This function creates the components\n",
        "\n",
        "def _make_question_components(\n",
        "    agent_name:str,\n",
        "    measurements: measurements_lib.Measurements,\n",
        "    model: language_model.LanguageModel,\n",
        "    clock: game_clock.MultiIntervalClock,\n",
        ") -\u003e Sequence[question_of_recent_memories.QuestionOfRecentMemories]:\n",
        "\n",
        "  question_1 = Question1(\n",
        "      agent_name=agent_name,\n",
        "      model=model,\n",
        "      logging_channel=measurements.get_channel('Question_1').on_next,\n",
        "  )\n",
        "  question_2 = Question2(\n",
        "      agent_name=agent_name,\n",
        "      model=model,\n",
        "      clock_now=clock.now,\n",
        "      logging_channel=measurements.get_channel('Question_2').on_next,\n",
        "  )\n",
        "  question_3 = Question3(\n",
        "      agent_name=agent_name,\n",
        "      model=model,\n",
        "      clock_now=clock.now,\n",
        "      logging_channel=measurements.get_channel('Question_3').on_next,\n",
        "  )\n",
        "\n",
        "  return (question_1, question_2, question_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2W9WkK1TM98K"
      },
      "outputs": [],
      "source": [
        "%%writefile -a my_agent.py\n",
        "\n",
        "def _get_class_name(object_: object) -\u003e str:\n",
        "  return object_.__class__.__name__\n",
        "\n",
        "#@markdown This function builds the agent using the components defined above. It also adds core components that are useful for every agent, like observations, time display, recenet memories.\n",
        "\n",
        "def build_agent(\n",
        "    config: formative_memories.AgentConfig,\n",
        "    model: language_model.LanguageModel,\n",
        "    memory: associative_memory.AssociativeMemory,\n",
        "    clock: game_clock.MultiIntervalClock,\n",
        "    update_time_interval: datetime.timedelta,\n",
        ") -\u003e entity_agent_with_logging.EntityAgentWithLogging:\n",
        "  \"\"\"Build an agent.\n",
        "\n",
        "  Args:\n",
        "    config: The agent config to use.\n",
        "    model: The language model to use.\n",
        "    memory: The agent's memory object.\n",
        "    clock: The clock to use.\n",
        "    update_time_interval: Agent calls update every time this interval passes.\n",
        "\n",
        "  Returns:\n",
        "    An agent.\n",
        "  \"\"\"\n",
        "  del update_time_interval\n",
        "  if not config.extras.get('main_character', False):\n",
        "    raise ValueError(\n",
        "        'This function is meant for a main character '\n",
        "        'but it was called on a supporting character.'\n",
        "    )\n",
        "\n",
        "  agent_name = config.name\n",
        "\n",
        "  raw_memory = legacy_associative_memory.AssociativeMemoryBank(memory)\n",
        "\n",
        "  measurements = measurements_lib.Measurements()\n",
        "  instructions = agent_components.instructions.Instructions(\n",
        "      agent_name=agent_name,\n",
        "      logging_channel=measurements.get_channel('Instructions').on_next,\n",
        "  )\n",
        "\n",
        "  time_display = agent_components.report_function.ReportFunction(\n",
        "      function=clock.current_time_interval_str,\n",
        "      pre_act_key='\\nCurrent time',\n",
        "      logging_channel=measurements.get_channel('TimeDisplay').on_next,\n",
        "  )\n",
        "\n",
        "  observation_label = '\\nObservation'\n",
        "  observation = agent_components.observation.Observation(\n",
        "      clock_now=clock.now,\n",
        "      timeframe=clock.get_step_size(),\n",
        "      pre_act_key=observation_label,\n",
        "      logging_channel=measurements.get_channel('Observation').on_next,\n",
        "  )\n",
        "  observation_summary_label = 'Summary of recent observations'\n",
        "  observation_summary = agent_components.observation.ObservationSummary(\n",
        "      model=model,\n",
        "      clock_now=clock.now,\n",
        "      timeframe_delta_from=datetime.timedelta(hours=4),\n",
        "      timeframe_delta_until=datetime.timedelta(hours=0),\n",
        "      pre_act_key=observation_summary_label,\n",
        "      logging_channel=measurements.get_channel('ObservationSummary').on_next,\n",
        "  )\n",
        "\n",
        "  relevant_memories_label = '\\nRecalled memories and observations'\n",
        "  relevant_memories = agent_components.all_similar_memories.AllSimilarMemories(\n",
        "      model=model,\n",
        "      components={\n",
        "          _get_class_name(observation_summary): observation_summary_label,\n",
        "          _get_class_name(time_display): 'The current date/time is'},\n",
        "      num_memories_to_retrieve=10,\n",
        "      pre_act_key=relevant_memories_label,\n",
        "      logging_channel=measurements.get_channel('AllSimilarMemories').on_next,\n",
        "  )\n",
        "\n",
        "  if config.goal:\n",
        "    goal_label = '\\nOverarching goal'\n",
        "    overarching_goal = agent_components.constant.Constant(\n",
        "        state=config.goal,\n",
        "        pre_act_key=goal_label,\n",
        "        logging_channel=measurements.get_channel(goal_label).on_next)\n",
        "  else:\n",
        "    goal_label = None\n",
        "    overarching_goal = None\n",
        "\n",
        "\n",
        "  question_components = _make_question_components(\n",
        "      agent_name=agent_name,\n",
        "      model=model,\n",
        "      clock=clock,\n",
        "      measurements=measurements\n",
        "  )\n",
        "\n",
        "  core_components = (\n",
        "      instructions,\n",
        "      time_display,\n",
        "      observation,\n",
        "      observation_summary,\n",
        "      relevant_memories,\n",
        "  )\n",
        "\n",
        "  entity_components = core_components + tuple(question_components)\n",
        "  components_of_agent = {\n",
        "      _get_class_name(component): component for component in entity_components\n",
        "  }\n",
        "\n",
        "  components_of_agent[\n",
        "      agent_components.memory_component.DEFAULT_MEMORY_COMPONENT_NAME\n",
        "  ] = agent_components.memory_component.MemoryComponent(raw_memory)\n",
        "  component_order = list(components_of_agent.keys())\n",
        "  if overarching_goal is not None:\n",
        "    components_of_agent[goal_label] = overarching_goal\n",
        "    # Place goal after the instructions.\n",
        "    component_order.insert(1, goal_label)\n",
        "\n",
        "  act_component = agent_components.concat_act_component.ConcatActComponent(\n",
        "      model=model,\n",
        "      clock=clock,\n",
        "      component_order=component_order,\n",
        "      logging_channel=measurements.get_channel('ActComponent').on_next,\n",
        "  )\n",
        "\n",
        "  agent = entity_agent_with_logging.EntityAgentWithLogging(\n",
        "      agent_name=agent_name,\n",
        "      act_component=act_component,\n",
        "      context_components=components_of_agent,\n",
        "      component_logging=measurements,\n",
        "  )\n",
        "\n",
        "  return agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xN_dpScXM98K"
      },
      "outputs": [],
      "source": [
        "agent_module = importlib.import_module('my_agent')\n",
        "!zip my_agent.zip my_agent.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTZjLHpYuwOQ"
      },
      "source": [
        "# The simulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNl5UpuHuwOQ"
      },
      "source": [
        "## Initialize the simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yBQcLSkjUab"
      },
      "outputs": [],
      "source": [
        "# @title Select a scenario\n",
        "from examples.modular.scenario import scenarios\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Get all the scenarios\n",
        "all_scenarios = [key for key in scenarios.SCENARIO_CONFIGS.keys()]\n",
        "\n",
        "# Create the dropdown widget\n",
        "dropdown = widgets.Dropdown(\n",
        "    options=all_scenarios,\n",
        "    value='haggling_0',\n",
        "    description='Select a scenario to run on:',\n",
        "    layout={'width': '500px'},  # Adjust the width as needed\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "# Display the widget\n",
        "display.display(dropdown)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CplEMApbgp7w"
      },
      "outputs": [],
      "source": [
        "SCEANRIO_NAME = dropdown.value\n",
        "print(f\"Selected scenario: {SCEANRIO_NAME}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCfIjcukuwOQ"
      },
      "outputs": [],
      "source": [
        "# @title Initialize the simulation\n",
        "measurements = measurements_lib.Measurements()\n",
        "runnable_simulation = scenarios.build_simulation(\n",
        "    scenarios.SCENARIO_CONFIGS[SCEANRIO_NAME],\n",
        "    model=model,\n",
        "    embedder=embedder,\n",
        "    measurements=measurements,\n",
        "    focal_agent_module=agent_module,\n",
        "    override_agent_model=call_limit_wrapper.CallLimitLanguageModel(model),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f0j8s-_uwOR"
      },
      "source": [
        "## Run the simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4Z1ttTfuwOR"
      },
      "outputs": [],
      "source": [
        "# @title Run the simulation\n",
        "simulation_outcome, results_log = runnable_simulation()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mo9elWtksbkV"
      },
      "outputs": [],
      "source": [
        "# @title Calculate and print the score of the agent on the scenario\n",
        "if scenarios.SCENARIO_CONFIGS[SCEANRIO_NAME].focal_is_resident:\n",
        "  total_score = sum(simulation_outcome.resident_scores.values()) / len(simulation_outcome.resident_scores.values())\n",
        "else:\n",
        "  total_score = sum(simulation_outcome.visitor_scores.values()) / len(simulation_outcome.visitor_scores.values())\n",
        "\n",
        "# Score is per-capita reward\n",
        "print('SCORE: ', total_score)"
      ]
    },
    {
      "metadata": {
        "id": "zzYt04V3cono"
      },
      "cell_type": "markdown",
      "source": [
        "The score above is the score of your agent on the spefic scenario. To evaluate it on all of the scenarios, use the following script:\n",
        "https://github.com/google-deepmind/concordia/blob/main/examples/modular/launch_concordia_challenge_evaluation.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXb_ay3wLg0k"
      },
      "outputs": [],
      "source": [
        "# @title Display the results log\n",
        "display.HTML(results_log)"
      ]
    },
    {
      "metadata": {
        "id": "iG0axBHXQSqA"
      },
      "cell_type": "code",
      "source": [
        "# @title Summarise the perspective of each player\n",
        "from IPython import display\n",
        "from concordia.utils import html as html_lib\n",
        "\n",
        "player_logs = []\n",
        "player_log_names = []\n",
        "for name, player_memory in (\n",
        "    runnable_simulation.get_all_player_memories().items()):\n",
        "  all_player_mem = list(player_memory.retrieve_recent(k=1000, add_time=True))\n",
        "  all_player_mem = ['Memories:'] + all_player_mem\n",
        "  player_html = html_lib.PythonObjectToHTMLConverter(all_player_mem).convert()\n",
        "  player_logs.append(player_html)\n",
        "  player_log_names.append(f'{name}')\n",
        "\n",
        "player_memories_html = html_lib.combine_html_pages(\n",
        "    player_logs,\n",
        "    player_log_names,\n",
        "    summary='',\n",
        "    title='Player Memories',\n",
        ")\n",
        "\n",
        "player_memories_html = html_lib.finalise_html(player_memories_html)\n",
        "display.HTML(player_memories_html)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaiIye0KuwOR"
      },
      "source": [
        "## Save the results log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDGkKpsruwOR"
      },
      "outputs": [],
      "source": [
        "# @title Write the results log as an HTML file in the current working directory.\n",
        "filename = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S') + '.html'\n",
        "file_handle = open(filename, 'a')\n",
        "file_handle.write(results_log)\n",
        "file_handle.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5EtZPP5gp7w"
      },
      "source": [
        "Now that you have successfully built an agent and have a greater understanding of agent components, we highly recommend exploring on your own. Remember, agent components are fully customizable. Check out the tutorial on components to learn more: https://github.com/google-deepmind/concordia/blob/main/examples/tutorials/agent_components_tutorial.ipynb\n",
        "\n",
        "To work with a more flexible .py file, navigate to concordia/factory/agent and duplicate the basic_agent.py file to get started or just copy the my_agent.py that was created by this colab, which is a valid agent factory.\n",
        "\n",
        "Agent factory: https://github.com/google-deepmind/concordia/tree/main/concordia/factory/agent\n",
        "\n",
        "\n",
        "Agent’s that are in the factory can be tested on the full set of scenarios by running the following script\n",
        "\n",
        "Script for full evaluation across substrates: https://github.com/google-deepmind/concordia/blob/main/examples/modular/launch_concordia_challenge_evaluation.py\n",
        "\n",
        "More Tutorials: https://github.com/google-deepmind/concordia/tree/main/examples/tutorials\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWDqd4ByzSsT"
      },
      "source": [
        "```\n",
        "Copyright 2023 DeepMind Technologies Limited.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
