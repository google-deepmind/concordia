# -*- coding: utf-8 -*-
"""agent_development.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mLBc6wUfKsuxupKrQmz0YgzzAVZp8uWe

# Agent development colab


This notebook presents a prompt engineering view of the Concordia agent development process, making it easier to configure within the Concordia environment. For coding proficient users, a higher level of customization and development will be possible by developing agents directly in the agent factory.


To begin, make a copy of this colab and save to google drive. This will impact where the agent file is created that you will eventually submit.


Agent Factory: https://github.com/google-deepmind/concordia/tree/main/concordia/factory/agent

Additional Agent Tutorials: https://github.com/google-deepmind/concordia/tree/main/examples/tutorials

<a href="https://colab.research.google.com/github/google-deepmind/concordia/blob/main/examples/tutorials/agent_development.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

## Setup and imports
"""

import sys
project_root = '/home/xinyuan/Documents/concordia'
sys.path.append(project_root)
path_to_concordia = sys.path[-1]

import datetime
import importlib
import numpy as np

from concordia.language_model import call_limit_wrapper
from concordia.language_model import utils
from concordia.utils import measurements as measurements_lib
import sentence_transformers

"""## Language Model setup

# API KEY

Codestral / Mistral / OpenAI

Links to where to generate API Key

Together AI = https://api.together.xyz/settings/api-keys

Mistral = https://console.mistral.ai/api-keys/

OpenAI = https://platform.openai.com/settings/profile?tab=api-keys (Profile -> API Keys) Note: GPT-4o models can be unwilling to participate in game structures resulting in worse performance.


Using API_TYPE='together_ai', MODEL_NAME='google/gemma-2-9b-it' is advised.


## Disable language model

Select ‘Disable language model’ when testing code functionality to prevent unnecessary cost and to save time.

## Parameters
"""

# @title Parameters (edit this cell)

# Pick API_TYPE from concordia/language_model/utils.py, e.g. mistral.
API_TYPE = 'together_ai'
# Add your API key here or alternatively, leave this as None to get it from an
# environment variable.
API_KEY = 'fe42d74db81151d2f44c1c3052f06d5f900151f7e2ced04b4901e9f3e1d75a1f' # @param {"type":"string"}
# Pick  a specific model e.g. gpt-4o if API_TYPE is openai, codestral-latest if
# API_TYPE is mistral. See the corresponding wrapper in concordia/language_model
# for links to the websites where the model names are listed for each API_TYPE.
# MODEL_NAME = 'meta-llama/Meta-Llama-3-8B-Instruct-Turbo'
# MODEL_NAME = 'meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo'
# MODEL_NAME = 'google/gemma-2-27b-it'
MODEL_NAME = 'google/gemma-2-9b-it'
# Select an embedder by specifying one of the sentence transformer embedding
# models listed at https://huggingface.co/sentence-transformers.
EMBEDDER_NAME = 'all-mpnet-base-v2'
# To debug without spending money on API calls, set DISABLE_LANGUAGE_MODEL=True.
DISABLE_LANGUAGE_MODEL = False # @param {"type":"boolean"}

# @title Language Model setup

model = utils.language_model_setup(
    api_type=API_TYPE,
    model_name=MODEL_NAME,
    api_key=API_KEY,
    disable_language_model=DISABLE_LANGUAGE_MODEL,
)

"""## Setup sentence encoder"""

# @title Setup sentence encoder

if DISABLE_LANGUAGE_MODEL:
  embedder = lambda x: np.ones(5)
else:
  _embedder_model = sentence_transformers.SentenceTransformer(
      f'sentence-transformers/{EMBEDDER_NAME}')
  embedder = lambda x: _embedder_model.encode(x, show_progress_bar=False)

"""# Building an agent"""

"""## Select Agent"""
args = sys.argv[1:]
agent_name = args[0] if len(args) > 0 else 'my_agent'
print(f"AGENT: {agent_name}")

IMPORT_AGENT_BASE_DIR = 'concordia.factory.agent'
agent_module = importlib.import_module(
    f'{IMPORT_AGENT_BASE_DIR}.{agent_name}'
)

"""# The simulation

## Initialize the simulation
"""

# @title Select a scenario
from examples.modular.scenario import scenarios

# Get all the scenarios
all_scenarios = [key for key in scenarios.SCENARIO_CONFIGS.keys()]
print("List of Scenarios:")
for key in scenarios.SCENARIO_CONFIGS.keys():
  print(f"- {key}")

SCEANRIO_NAME = 'haggling_0'
# SCEANRIO_NAME = 'haggling_multi_item_0'
# SCEANRIO_NAME = 'pub_coordination_0'
# SCEANRIO_NAME = 'labor_collective_action__paranoid_boss_0'
# SCEANRIO_NAME = 'reality_show_circa_2003_stag_hunt_0'
# SCEANRIO_NAME = 'state_formation_0'
print(f"Selected Scenario: {SCEANRIO_NAME}")

# @title Initialize the simulation
measurements = measurements_lib.Measurements()
runnable_simulation = scenarios.build_simulation(
    scenarios.SCENARIO_CONFIGS[SCEANRIO_NAME],
    model=model,
    embedder=embedder,
    measurements=measurements,
    focal_agent_module=agent_module,
    override_agent_model=call_limit_wrapper.CallLimitLanguageModel(model),
    seed = 0, # random seed for GM
)

"""## Run the simulation"""

# @title Run the simulation
simulation_outcome, results_log = runnable_simulation()

# @title Calculate and print the score of the agent on the scenario
if scenarios.SCENARIO_CONFIGS[SCEANRIO_NAME].focal_is_resident:
  total_score = sum(simulation_outcome.resident_scores.values()) / len(simulation_outcome.resident_scores.values())
else:
  total_score = sum(simulation_outcome.visitor_scores.values()) / len(simulation_outcome.visitor_scores.values())

# Score is per-capita reward
print('SCORE: ', total_score)

# @titel Write the score in a text file
log_prefix = path_to_concordia + '/data/'
time_now = datetime.datetime.now().strftime('%d %H:%M')

filename = log_prefix + 'score.txt'
title = f'[{SCEANRIO_NAME}] {agent_name} {time_now}\n'

file_handle = open(filename, 'a')
file_handle.write(title)
file_handle.write(f">>> {total_score}\n")
file_handle.write('-----\n')
file_handle.close()

"""The score above is the score of your agent on the specific scenario. To evaluate

---

it on all of the scenarios, use the following script:
https://github.com/google-deepmind/concordia/blob/main/examples/modular/launch_concordia_challenge_evaluation.py

"""

"""## Save the results log"""

# @title Write the results log as an HTML file in the current working directory.
filename = f'{log_prefix}{time_now} {SCEANRIO_NAME} {agent_name}.html'
file_handle = open(filename, 'a')
file_handle.write(results_log)
file_handle.close()

"""Now that you have successfully built an agent and have a greater understanding of agent components, we highly recommend exploring on your own. Remember, agent components are fully customizable. Check out the tutorial on components to learn more: https://github.com/google-deepmind/concordia/blob/main/examples/tutorials/agent_components_tutorial.ipynb

To work with a more flexible .py file, navigate to concordia/factory/agent and duplicate the basic_agent.py file to get started or just copy the my_agent.py that was created by this colab, which is a valid agent factory.

Agent factory: https://github.com/google-deepmind/concordia/tree/main/concordia/factory/agent


Agent’s that are in the factory can be tested on the full set of scenarios by running the following script

Script for full evaluation across substrates: https://github.com/google-deepmind/concordia/blob/main/examples/modular/launch_concordia_challenge_evaluation.py

More Tutorials: https://github.com/google-deepmind/concordia/tree/main/examples/tutorials

```
Copyright 2023 DeepMind Technologies Limited.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    https://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
```
"""
